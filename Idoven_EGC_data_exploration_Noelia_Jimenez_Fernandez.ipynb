{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wfdb\n",
        "!pip install ecg_plot\n",
        "!pip install xgboost==1.7.6"
      ],
      "metadata": {
        "id": "GyzZ2byMsNk2"
      },
      "id": "GyzZ2byMsNk2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee7095b2",
      "metadata": {
        "scrolled": true,
        "id": "ee7095b2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import wfdb\n",
        "import numpy as np\n",
        "import ecg_plot\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import xgboost as xgb\n",
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, roc_auc_score, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3061bb5",
      "metadata": {
        "id": "b3061bb5"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b903551",
      "metadata": {
        "id": "6b903551"
      },
      "source": [
        "Fist of all data are loaded using 'example_physionet.py' code with some modifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4cfa8ed",
      "metadata": {
        "id": "e4cfa8ed"
      },
      "outputs": [],
      "source": [
        "path = 'https://physionet.org/files/ptb-xl/1.0.2/'\n",
        "sampling_rate=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76f513b0",
      "metadata": {
        "id": "76f513b0"
      },
      "outputs": [],
      "source": [
        "# load and convert annotation data\n",
        "annotations = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
        "annotations.scp_codes = annotations.scp_codes.apply(lambda x: ast.literal_eval(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40b07903",
      "metadata": {
        "id": "40b07903"
      },
      "outputs": [],
      "source": [
        "# Load scp_statements.csv for diagnostic aggregation\n",
        "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9418dfd3",
      "metadata": {
        "id": "9418dfd3"
      },
      "outputs": [],
      "source": [
        "def aggregate_diagnostic(y_dic):\n",
        "    tmp = []\n",
        "    for key in y_dic.keys():\n",
        "        if key in agg_df.index:\n",
        "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
        "    return list(set(tmp))\n",
        "\n",
        "# Apply diagnostic superclass\n",
        "annotations['diagnostic_superclass'] = annotations.scp_codes.apply(aggregate_diagnostic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afef89d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afef89d3",
        "outputId": "5c9125c1-6a1c-4197-8df3-b98d71ab4107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n"
          ]
        }
      ],
      "source": [
        "def load_raw_data(df, sampling_rate, path):\n",
        "    data = []\n",
        "    for i, f in enumerate(df.filename_lr):\n",
        "        folder = int(f.split('/')[-1].split('_')[0]) // 1000 * 1000\n",
        "        file = f.split('/')[-1]\n",
        "        localfile = path + f\"records{sampling_rate}/{folder:05d}/{file}\"\n",
        "        if i%1000 == 0:\n",
        "            print(i)\n",
        "        try:\n",
        "            if os.path.exists(localfile):\n",
        "                datum = wfdb.rdsamp(f\"{localfile}/\")\n",
        "            else:\n",
        "                datum = wfdb.rdsamp(file, pn_dir=f\"ptb-xl/1.0.2/records{sampling_rate}/{folder:05d}/\")\n",
        "            data.append(datum)\n",
        "        except wfdb.io._url.NetFileNotFoundError:\n",
        "            data.append([np.empty((0, 0), dtype=object), {}])\n",
        "            continue\n",
        "    return np.array([signal for signal, meta in data])\n",
        "# Load raw signal data\n",
        "# If the file exists locally, it load it, if not it looks on the server to get the data and process them\n",
        "if not os.path.exists(\"raw_annotations.pickle\"):\n",
        "  raw_data = load_raw_data(annotations, sampling_rate, path)\n",
        "  def transpose(x):\n",
        "    return x.T\n",
        "  traspose_raw_data = list(map(transpose, raw_data))\n",
        "  annotations['waveforms'] = pd.Series(traspose_raw_data)\n",
        "  annotations.to_pickle(\"raw_annotations.pickle\")\n",
        "else:\n",
        "  annotations = pd.read_pickle('raw_annotations.pickle')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05540f73",
      "metadata": {
        "id": "05540f73"
      },
      "source": [
        "Now that data and annotations are loaded into a dataframe and a numpy array respectively, they can be shown to a doctor asking him for the required number of record and sampling frequency ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54fea479",
      "metadata": {
        "id": "54fea479"
      },
      "outputs": [],
      "source": [
        "ecg_id = int(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "annotations_without_waveforms = annotations.loc[:, annotations.columns != 'waveforms']"
      ],
      "metadata": {
        "id": "13PeB9ygQ70u"
      },
      "id": "13PeB9ygQ70u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bc1b272d",
      "metadata": {
        "id": "bc1b272d"
      },
      "source": [
        "Information about the required record is shown:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9bb2022",
      "metadata": {
        "id": "c9bb2022"
      },
      "source": [
        "#### Annotations and plot for a record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92fca22c",
      "metadata": {
        "scrolled": true,
        "id": "92fca22c"
      },
      "outputs": [],
      "source": [
        "def get_record_data(record_id):\n",
        "    return annotations.iloc[record_id]\n",
        "get_record_data(ecg_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f18011b",
      "metadata": {
        "id": "1f18011b"
      },
      "source": [
        "for the same record the ECG is plotted using ecg_plot library:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d561ce20",
      "metadata": {
        "id": "d561ce20"
      },
      "source": [
        "#### Plotted signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d706b64b",
      "metadata": {
        "id": "d706b64b"
      },
      "outputs": [],
      "source": [
        "def plot_signal(data, record_id):\n",
        "    signal = data[record_id]\n",
        "    # Plot the ECG signal\n",
        "    ecg_plot.plot(signal, sample_rate=sampling_rate, title=\"ECG Signal, Record \"+str(record_id), show_lead_name=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6781c592",
      "metadata": {
        "id": "6781c592"
      },
      "outputs": [],
      "source": [
        "plot_signal(annotations['waveforms'], ecg_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47f74054",
      "metadata": {
        "id": "47f74054"
      },
      "source": [
        "## Exploratory Data Analysis and basic cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9f62705",
      "metadata": {
        "id": "b9f62705"
      },
      "outputs": [],
      "source": [
        "annotations.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6acfd8c8",
      "metadata": {
        "scrolled": true,
        "id": "6acfd8c8"
      },
      "outputs": [],
      "source": [
        "annotations.tail(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4beb568",
      "metadata": {
        "scrolled": true,
        "id": "f4beb568"
      },
      "outputs": [],
      "source": [
        "annotations.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3ba00b7",
      "metadata": {
        "id": "f3ba00b7"
      },
      "source": [
        "Since indexes are not matching, they will be reset so 'ecg_id' becomes a column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "691baf2f",
      "metadata": {
        "id": "691baf2f"
      },
      "outputs": [],
      "source": [
        "annotations = annotations.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c1b0ef7",
      "metadata": {
        "scrolled": true,
        "id": "0c1b0ef7"
      },
      "outputs": [],
      "source": [
        "annotations.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "726d0359",
      "metadata": {
        "id": "726d0359"
      },
      "outputs": [],
      "source": [
        "annotations_without_waveforms.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22db382",
      "metadata": {
        "id": "f22db382"
      },
      "source": [
        "We see that there are some  values of age that are wrong, since the maximum is 300 years. Since the origin of this mistake is unknown, let's remove these rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3529a936",
      "metadata": {
        "id": "3529a936"
      },
      "outputs": [],
      "source": [
        "annotations[annotations.age>120].age.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d1eb456",
      "metadata": {
        "id": "8d1eb456"
      },
      "outputs": [],
      "source": [
        "annotations[annotations.age>120].index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52018918",
      "metadata": {
        "id": "52018918"
      },
      "source": [
        "These indexes must also be removed from X (records of ECG signals)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c471da9c",
      "metadata": {
        "id": "c471da9c"
      },
      "outputs": [],
      "source": [
        "annotations_age_clean = annotations.drop(annotations[annotations.age>120].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3386332e",
      "metadata": {
        "id": "3386332e"
      },
      "outputs": [],
      "source": [
        "annotations_age_clean.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0a10c6a",
      "metadata": {
        "id": "e0a10c6a"
      },
      "source": [
        "Also, 30 rows seem to have had electrodes problems, and then will be removed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32276df8",
      "metadata": {
        "id": "32276df8"
      },
      "outputs": [],
      "source": [
        "annotations_electrodes_clean = annotations_age_clean[annotations_age_clean.electrodes_problems.isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f33e3337",
      "metadata": {
        "id": "f33e3337"
      },
      "outputs": [],
      "source": [
        "annotations_electrodes_clean.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "annotations_clean = annotations_electrodes_clean"
      ],
      "metadata": {
        "id": "whbVa0LtSeeP"
      },
      "id": "whbVa0LtSeeP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c9a8efb7",
      "metadata": {
        "id": "c9a8efb7"
      },
      "source": [
        "### Demographics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f915de32",
      "metadata": {
        "id": "f915de32"
      },
      "outputs": [],
      "source": [
        "annotations_clean.age.plot(kind='hist')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc57754b",
      "metadata": {
        "id": "bc57754b"
      },
      "outputs": [],
      "source": [
        "annotations_clean.sex.value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "839491ee",
      "metadata": {
        "id": "839491ee"
      },
      "outputs": [],
      "source": [
        "annotations_clean.site.value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbbcb0a2",
      "metadata": {
        "scrolled": true,
        "id": "dbbcb0a2"
      },
      "outputs": [],
      "source": [
        "annotations_clean.device.value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b8bfc9b",
      "metadata": {
        "scrolled": true,
        "id": "3b8bfc9b"
      },
      "outputs": [],
      "source": [
        "annotations_clean.nurse.value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74117558",
      "metadata": {
        "id": "74117558"
      },
      "outputs": [],
      "source": [
        "annotations_clean.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05563b74",
      "metadata": {
        "id": "05563b74"
      },
      "outputs": [],
      "source": [
        "annotations_clean[annotations_clean.height.notna()].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7b39a9a",
      "metadata": {
        "id": "b7b39a9a"
      },
      "outputs": [],
      "source": [
        "annotations_clean[annotations_clean.weight.notna()].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7ce47ae",
      "metadata": {
        "id": "d7ce47ae"
      },
      "source": [
        "### Diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "annotations_clean_without_waveform = annotations_clean.loc[:, annotations_clean.columns != 'waveforms']"
      ],
      "metadata": {
        "id": "BLRPm0hQS4xd"
      },
      "id": "BLRPm0hQS4xd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab93bf2d",
      "metadata": {
        "scrolled": true,
        "id": "ab93bf2d"
      },
      "outputs": [],
      "source": [
        "annotations_value_counts = annotations_clean_without_waveform.diagnostic_superclass.value_counts()\n",
        "annotations_value_counts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "complete_annotations_value_counts = [x for x in sum(annotations_value_counts.index.to_list(), []) if str(x) != 'nan']"
      ],
      "metadata": {
        "id": "AGa0V0PLaDWR"
      },
      "id": "AGa0V0PLaDWR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diagnosis_set = set(complete_annotations_value_counts)\n",
        "diagnosis_set"
      ],
      "metadata": {
        "id": "vRydo67gUW4X"
      },
      "id": "vRydo67gUW4X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d1c06ad8",
      "metadata": {
        "id": "d1c06ad8"
      },
      "source": [
        "Since each record can have several classifications, a count of number of records in each group of diagnosis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f610d0cb",
      "metadata": {
        "id": "f610d0cb"
      },
      "outputs": [],
      "source": [
        "diagnosis_count = dict()\n",
        "for diagnosis_type in diagnosis_set:\n",
        "    diagnosis_count[diagnosis_type] = complete_annotations_value_counts.count(diagnosis_type)\n",
        "diagnosis_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c19e7797",
      "metadata": {
        "id": "c19e7797"
      },
      "outputs": [],
      "source": [
        "labels = list(diagnosis_count.keys())[1:]\n",
        "values = list(diagnosis_count.values())[1:]\n",
        "plt.pie(values, labels=labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "367a1f66",
      "metadata": {
        "id": "367a1f66"
      },
      "source": [
        "### Conclusions after preliminary exporation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3b8529a",
      "metadata": {
        "id": "d3b8529a"
      },
      "source": [
        "A basic cleaning has been done to the dataset removing dirty values for age and rows with problems in electrodes. 21479 out of the initial 21801 rows remain. In this prelimiary exploration it also has been seen that rows as height and weight have values just in 6811 and 9259 of the rows, so this will be taken into account when a model is trained, depending how the chosen one deals with null values. Also, some columns such as 'site' or 'nurse' have few variations, and will probably not make a difference for the target value. It has also been seen that other variables such as sex, age, or the target value, the dataset is quite balanced.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "902f94cd",
      "metadata": {
        "id": "902f94cd"
      },
      "source": [
        "## Identifying the heart beat of the signal, average and total heart beat in the signal"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this sections mean heart beat is calculated through the function 'get_heart_rate' for one waveform in each record. Also QRS duration and amplitude is calculated through applying 'get_qrs_duration_and_amplitude'. QRS VAT or other parameters regarding QRS used to detect abnormalities that can be calculated remain to be calculated in future versions."
      ],
      "metadata": {
        "id": "lOo4jRLfsf_f"
      },
      "id": "lOo4jRLfsf_f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde10ec5",
      "metadata": {
        "id": "cde10ec5"
      },
      "outputs": [],
      "source": [
        "# Calculate the number of points between each peak and the next, multiplies them by the period of each point, getting the time between succesive peaks.\n",
        "# Afterwards, it averages that time, inverse it to obtain the frequency per second, and multiplies by 60 to obtain frequency per minute.\n",
        "def get_heart_rate(peaks, fs):\n",
        "    time_period_per_point = 1 / fs\n",
        "    hearbeat_period = sum(\n",
        "        (peaks[index + 1] - peaks[index]) * time_period_per_point\n",
        "        for index in range(len(peaks) - 1)\n",
        "    ) / len(peaks)\n",
        "\n",
        "    return 60. / hearbeat_period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ed13c06",
      "metadata": {
        "id": "1ed13c06"
      },
      "outputs": [],
      "source": [
        "# Helper function for returning a pandas Series\n",
        "def get_qrs_duration_and_amplitude_row(row, fs):\n",
        "    qrs_duration, qrs_amplitude = get_qrs_duration_and_amplitude(row['waveforms'][11], row['r_peaks'], fs)\n",
        "\n",
        "    row['qrs_duration'] = qrs_duration\n",
        "    row['qrs_amplitude'] = qrs_amplitude\n",
        "    return row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4848531c",
      "metadata": {
        "id": "4848531c"
      },
      "outputs": [],
      "source": [
        "# Obtaines the QRS duration and amplitude\n",
        "def get_qrs_duration_and_amplitude(waveform, peaks, fs):\n",
        "\n",
        "    # Divides the waveform by the middle point between peaks, returning a subset of waveforms with each peak in the middle of it\n",
        "    def chunk_waveform(waveform, peaks):\n",
        "        chunks = []\n",
        "        for index in range(1, len(peaks) - 1):\n",
        "            prev_distance = peaks[index] - peaks[index - 1]\n",
        "            next_distance = peaks[index + 1] - peaks[index]\n",
        "            prev_cut_point = peaks[index - 1] + int(prev_distance / 2)\n",
        "            next_cut_point = peaks[index] + int(next_distance / 2)\n",
        "            chunk = waveform[prev_cut_point: next_cut_point]\n",
        "            chunks.append(chunk)\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    # Counts how many points there are at the left part of the peak until the absolute value of the signal is increased more than a 5% of the peak value\n",
        "    # Afterwards, multiplies those points by the inverse of the sampling frequency to obtain the time\n",
        "    def get_q_start(chunk, fs, threshold = 0.05):\n",
        "        time_period_per_point = 1 / fs\n",
        "        peak = max(chunk)\n",
        "        initial_value = sum(chunk[:6]) / len(chunk[:6])\n",
        "        low_points = 0\n",
        "        for index, point in enumerate(chunk):\n",
        "            if abs(point - initial_value) <= peak * threshold:\n",
        "                low_points += 1\n",
        "            else:\n",
        "                break\n",
        "        return low_points * time_period_per_point\n",
        "\n",
        "    # Counts how many points there are at the right part of the peak until the absolute value of the signal is increased more than a 5% of the peak value\n",
        "    # Afterwards, multiplies those points by the inverse of the sampling frequency to obtain the time\n",
        "    def get_s_finish(chunk, fs, threshold = 0.05):\n",
        "        inverted_chunk = chunk[::-1]\n",
        "        time_period_per_point = 1 / fs\n",
        "        peak = max(inverted_chunk)\n",
        "        initial_value = sum(inverted_chunk[:6]) / len(inverted_chunk[:6])\n",
        "        low_points = 0\n",
        "        for index, point in enumerate(inverted_chunk):\n",
        "            if abs(point - initial_value) <= peak * threshold:\n",
        "                low_points += 1\n",
        "            else:\n",
        "                break\n",
        "        return low_points * time_period_per_point\n",
        "\n",
        "    chunks = chunk_waveform(waveform, peaks)\n",
        "    qrs_duration = 0\n",
        "    qrs_amplitude = 0\n",
        "    # For each peak we calculate the time of the signal that is over 5% of the initial value\n",
        "    for chunk in chunks:\n",
        "        qrs_amplitude += max(chunk) - min(chunk)\n",
        "        time_period_per_point = 1 / 100\n",
        "        period = len(chunk) * time_period_per_point\n",
        "        duration = period - get_q_start(chunk, fs) - get_s_finish(chunk, fs)\n",
        "        qrs_duration += duration\n",
        "    qrs_amplitude /= len(chunks)\n",
        "    qrs_duration /= len(chunks)\n",
        "\n",
        "    return qrs_duration, qrs_amplitude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce38e2d5",
      "metadata": {
        "id": "ce38e2d5"
      },
      "outputs": [],
      "source": [
        "annotations_clean.r_peaks = annotations_clean.r_peaks.apply(lambda x: ast.literal_eval(x.replace('  ', ' ').replace('[ ', '[').replace(' ', ',').replace(',,', ',')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f530226",
      "metadata": {
        "id": "2f530226"
      },
      "outputs": [],
      "source": [
        "annotations_clean['heart_rate'] = annotations_clean.r_peaks.apply(lambda x: get_heart_rate(x, sampling_rate))\n",
        "annotations_clean_all_waveforms = annotations_clean[annotations_clean['waveforms'].apply(lambda x: not isinstance(x, float))]\n",
        "annotations_clean_all_waveforms = annotations_clean_all_waveforms.apply(lambda row: get_qrs_duration_and_amplitude_row(row, sampling_rate), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a model"
      ],
      "metadata": {
        "id": "sKfPbVg3vRuW"
      },
      "id": "sKfPbVg3vRuW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset with all the calculated parameters is now used to train an XGBoost Classifier and performance achieved reviewed."
      ],
      "metadata": {
        "id": "lP5FGGsOve1k"
      },
      "id": "lP5FGGsOve1k"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since various records are classified with several categories the dataset is exploded to get a set of records with one classification for the training."
      ],
      "metadata": {
        "id": "dITCH3-kvxZA"
      },
      "id": "dITCH3-kvxZA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3348cb1",
      "metadata": {
        "id": "a3348cb1"
      },
      "outputs": [],
      "source": [
        "annotations_clean_exploded = annotations_clean_all_waveforms.explode('diagnostic_superclass').dropna(subset=['diagnostic_superclass'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CR01OQKJvQLU"
      },
      "id": "CR01OQKJvQLU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482256d4",
      "metadata": {
        "id": "482256d4"
      },
      "outputs": [],
      "source": [
        "annotations_clean_exploded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f87cee1b",
      "metadata": {
        "id": "f87cee1b"
      },
      "outputs": [],
      "source": [
        "category_columns = ['heart_axis', 'diagnostic_superclass']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "307b6945",
      "metadata": {
        "id": "307b6945"
      },
      "outputs": [],
      "source": [
        "# columns = ['strat_fold', 'age', 'sex', 'height', 'weight', 'nurse','site', 'device', 'heart_axis', 'second_opinion', 'initial_autogenerated_report', 'validated_by_human', 'baseline_drift', 'static_noise', 'burst_noise', 'extra_beats', 'pacemaker','diagnostic_superclass', 'heart_rate', 'qrs_duration', 'qrs_amplitude']\n",
        "columns = ['strat_fold', 'age', 'sex', 'heart_axis', 'diagnostic_superclass', 'heart_rate', 'qrs_duration', 'qrs_amplitude']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0623a917",
      "metadata": {
        "id": "0623a917"
      },
      "outputs": [],
      "source": [
        "data = annotations_clean_exploded[columns].copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "annotations_clean_exploded['diagnostic_superclass']"
      ],
      "metadata": {
        "id": "INnkc3HHgtSV"
      },
      "id": "INnkc3HHgtSV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoders = {}\n",
        "for column in category_columns:\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  data[column] = le.fit_transform(data[column])\n",
        "  label_encoders[column] = le"
      ],
      "metadata": {
        "id": "NXFks29PTJ-t"
      },
      "id": "NXFks29PTJ-t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "771b4992",
      "metadata": {
        "id": "771b4992"
      },
      "outputs": [],
      "source": [
        "test_fold = 10\n",
        "valid_fold = 10\n",
        "data_train = data[(data['strat_fold'] != test_fold) & (data['strat_fold'] != valid_fold)]\n",
        "data_test = data[data['strat_fold'] == test_fold]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7da9846",
      "metadata": {
        "id": "e7da9846"
      },
      "outputs": [],
      "source": [
        "x_train = data_train.loc[:, data_train.columns != 'diagnostic_superclass']\n",
        "x_test = data_test.loc[:, data_test.columns != 'diagnostic_superclass']\n",
        "x_valid = data_valid.loc[:, data_valid.columns != 'diagnostic_superclass']\n",
        "y_train = data_train[['diagnostic_superclass']]\n",
        "y_test = data_test[['diagnostic_superclass']]\n",
        "y_valid = data_valid[['diagnostic_superclass']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_classifier = xgb.XGBClassifier(eta=0.006)\n",
        "xgb_classifier.fit(x_train, y_train)\n",
        "y_pred = xgb_classifier.predict(x_test)"
      ],
      "metadata": {
        "id": "8eIWKGEba-8z"
      },
      "id": "8eIWKGEba-8z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "metadata": {
        "id": "S5TlsqMWcvD8"
      },
      "id": "S5TlsqMWcvD8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred, labels=xgb_classifier.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(label_encoders['diagnostic_superclass'].inverse_transform(xgb_classifier.classes_)))\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Er8MBAdTZ-jy"
      },
      "id": "Er8MBAdTZ-jy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0Vcq3_KZA-ra"
      },
      "id": "0Vcq3_KZA-ra"
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we pay attention to the results obtained we would notice that just 44% of accuracy is achieved. This accuracy is nonetheless obscured by the fact that some of the records were originally classified in several categories. This fact might need a deeper study, since perhaps a multilabel model could work better."
      ],
      "metadata": {
        "id": "ScrTHyCokBvD"
      },
      "id": "ScrTHyCokBvD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some conclusions and future steps\n",
        "\n",
        "I have tried to create a comprehensive project in the limited time I had, trying to get an overview of the problem, studying the available data and creating a process that is able to use that data and predict a possible diagnosis from the kind of information that this dataset has.\n",
        "\n",
        "* I checked the library 'wfdb', which has some methods for processing these datasets and representing the electrocardiography in a doctor-friendly way. Sadly, the use of these methods required the annotations to be in a format different from the existing one, which was loaded from a .csv file. A method could probably be developed to convert the available annotations into a compatible format, but I  prefered to focus my efforts on more data-related tasks.\n",
        "* I created some functions to extract the average hearbeat from the available data (which was quite straightforward, since the peaks indexes are contained in the annotations) and to calculate the QRS duration and amplitude from the V6 signal, with the objective of using them to represent the information from the electrocardiographies in classification model. As a future development, more methods can be built to extract more data from the rest of voltage signals regarding the QRS complex, which can be used to train better models.\n",
        "* I did a first study on the variables contained in the dataset, which then I used together with the calculated parameters to train a classification model (XGBoost Classifier) with basic parameters, and a more advanced tuning and feature selection should be done in the future.\n",
        "* As continuation of the project, more models should be trained and compared between them to find the one that fits our data best. One of these models should be an LSTM, which would be suited to represent the information from the electrocardiographies much better than any parameter extraction.\n"
      ],
      "metadata": {
        "id": "T205H-yVihGx"
      },
      "id": "T205H-yVihGx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sources of information for the project were:\n",
        "- https://wfdb.readthedocs.io/\n",
        "- https://en.wikipedia.org/wiki/QRS_complex"
      ],
      "metadata": {
        "id": "rhfSFiOvABau"
      },
      "id": "rhfSFiOvABau"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}